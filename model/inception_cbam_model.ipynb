{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:10:02.753509Z",
     "start_time": "2024-01-26T12:09:58.730181600Z"
    }
   },
   "id": "301a92722ba16959",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 4GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "                                                                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:10:05.781128800Z",
     "start_time": "2024-01-26T12:10:05.775128500Z"
    }
   },
   "id": "e76c055a552574c6",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Implementation start"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4731bd99153a970f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:10:05.810633600Z",
     "start_time": "2024-01-26T12:10:05.783214500Z"
    }
   },
   "id": "c88128401d368777",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('./pkl_files/enchanced/validation/en_val_data.pkl', 'rb') as f:\n",
    "    val_img_arr = pickle.load(f)\n",
    "with open('./pkl_files/enchanced/validation/en_val_data_age.pkl', 'rb') as f:\n",
    "    val_bone_age_arr = pickle.load(f)\n",
    "with open('./pkl_files/enchanced/validation/en_val_data_gender.pkl', 'rb') as f:\n",
    "    val_gender_arr = pickle.load(f)\n",
    "\n",
    "images_arr_val = np.array(val_img_arr)\n",
    "bone_age_val = np.array(val_bone_age_arr)\n",
    "gender_val = np.array(val_gender_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:10:06.173202Z",
     "start_time": "2024-01-26T12:10:05.801216600Z"
    }
   },
   "id": "dbb52d8549fc6430",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('./pkl_files/enchanced/training/en_train_data.pkl', 'rb') as f:\n",
    "    train_img_arr = pickle.load(f)\n",
    "with open('./pkl_files/enchanced/training/en_train_data_age.pkl', 'rb') as f:\n",
    "    train_bone_age_arr = pickle.load(f)\n",
    "with open('./pkl_files/enchanced/training/en_train_data_gender.pkl', 'rb') as f:\n",
    "    train_gender_arr = pickle.load(f)\n",
    "\n",
    "images_arr_train = np.array(train_img_arr)\n",
    "bone_age_train = np.array(train_bone_age_arr)\n",
    "gender_train = np.array(train_gender_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:10:16.657443700Z",
     "start_time": "2024-01-26T12:10:10.961392Z"
    }
   },
   "id": "39a25e00b365b16",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: ( 12611 ,  12611 )\n",
      "\n",
      "Validation set: ( 1425 ,  1425 )\n"
     ]
    }
   ],
   "source": [
    "X_train = images_arr_train\n",
    "X_val = images_arr_val\n",
    "y_train = (bone_age_train-np.min(bone_age_train))/(np.max(bone_age_train)-np.min(bone_age_train))\n",
    "y_val = (bone_age_val-np.min(bone_age_val))/(np.max(bone_age_val)-np.min(bone_age_val))\n",
    "print(\"Training set: (\",len(X_train),\", \",len(y_train),\")\\n\")\n",
    "print(\"Validation set: (\",len(X_val),\", \",len(y_val),\")\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:10:16.672055100Z",
     "start_time": "2024-01-26T12:10:16.660547900Z"
    }
   },
   "id": "91c717eba708eaff",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.utils import plot_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:10:16.703079500Z",
     "start_time": "2024-01-26T12:10:16.676285900Z"
    }
   },
   "id": "54a01d990e7c5c00",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, Input, Flatten, Dropout\n",
    "from tensorflow.keras.layers import Activation, Concatenate, Conv2D, Multiply\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "import keras\n",
    "from keras.applications.inception_v3 import preprocess_input"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:10:16.704271600Z",
     "start_time": "2024-01-26T12:10:16.689894700Z"
    }
   },
   "id": "7c626726b94aaf74",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Channel Attention Module\n",
    "def channel_attention_module(x, ratio=8):\n",
    "\n",
    "    batch,_,_,channel=x.shape\n",
    "    # shared layers\n",
    "    l1 = Dense(channel//ratio, activation=\"relu\", use_bias=False)\n",
    "    l2 = Dense(channel, use_bias= False)\n",
    "\n",
    "    x1 = GlobalAveragePooling2D()(x)\n",
    "    x1 = Flatten()(x1)\n",
    "    x1 = l1(x1)\n",
    "    x1 = l2(x1)\n",
    "\n",
    "    x2 = GlobalMaxPooling2D()(x)\n",
    "    x2 = Flatten()(x2)\n",
    "    x2 = l1(x2)\n",
    "    x2 = l2(x2)\n",
    "\n",
    "    feats = x1 + x2\n",
    "    feats = Activation(\"sigmoid\")(feats)\n",
    "    feats = Multiply()([x,feats])\n",
    "\n",
    "    return feats"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:10:16.755887100Z",
     "start_time": "2024-01-26T12:10:16.706315400Z"
    }
   },
   "id": "c0eaebc7d3f63711",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# spatical attention module\n",
    "\n",
    "def spatial_attention_module(x):\n",
    "    # Average Pooling\n",
    "    x1 = tf.reduce_mean(x,axis = -1)\n",
    "    x1 = tf.expand_dims(x1,axis = -1)\n",
    "\n",
    "    # max pooling\n",
    "    x2 = tf.reduce_max(x, axis = -1)\n",
    "    x2 = tf.expand_dims(x2,axis=-1)\n",
    "\n",
    "    feats = Concatenate()([x1,x2])\n",
    "\n",
    "    feats = Conv2D(1,kernel_size=7, padding=\"same\",activation=\"softmax\")(feats)\n",
    "    feats = Multiply()([x,feats])\n",
    "\n",
    "    return feats"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:10:16.760573900Z",
     "start_time": "2024-01-26T12:10:16.721179600Z"
    }
   },
   "id": "b4c0fd3138cf613c",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Cbam module\n",
    "def cbam(x):\n",
    "    x = channel_attention_module(x)\n",
    "    x = spatial_attention_module(x)\n",
    "\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:10:16.760573900Z",
     "start_time": "2024-01-26T12:10:16.735899300Z"
    }
   },
   "id": "dff0db860d71c42e",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def build_image_model():\n",
    "    base_model = InceptionV3(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(299,299,3)\n",
    "    )\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    x = cbam(base_model.output)\n",
    "\n",
    "    x= GlobalAveragePooling2D()(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:10:16.771151Z",
     "start_time": "2024-01-26T12:10:16.753741800Z"
    }
   },
   "id": "a7f112e5b096c0e5",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model implementation End\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35ae824d6d9fdd78"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "class RoiExtractor:\n",
    "    def __init__(self):\n",
    "        # Model initialization\n",
    "        self.model = build_image_model()\n",
    "        self.model.load_weights('./saved_weights/best_final_5.h5')\n",
    "        self.heatmap_model = Model(inputs=self.model.inputs, outputs=self.model.layers[-3].output)\n",
    "\n",
    "        # Outputs\n",
    "        self.heatmap_1 = None\n",
    "        self.carpal_img = None\n",
    "        \n",
    "        self.heatmap_2 = None\n",
    "        self.metacarpal_img = None\n",
    "        \n",
    "        self.img = None\n",
    "        self.masked_img = None\n",
    "\n",
    "    def generate_heatmap(self, img):\n",
    "        \n",
    "        # Preprocessing\n",
    "        i = preprocess_input(img)\n",
    "        preprocessed_img = np.expand_dims(i, axis=0)\n",
    "\n",
    "        cbam_output = self.heatmap_model.predict(preprocessed_img)[0]\n",
    "\n",
    "        #Heatmap generation\n",
    "        heatmap = np.sum(cbam_output, axis=-1)\n",
    "        heatmap = (heatmap - np.min(heatmap)) / (np.max(heatmap) - np.min(heatmap))\n",
    "        upsampled_heatmap = cv2.resize(heatmap, (299, 299))\n",
    "        return upsampled_heatmap\n",
    "\n",
    "\n",
    "    def get_bounding_box(self, heatmap, threshold=0.7):\n",
    "        binary_mask = (heatmap > threshold).astype(np.uint8)\n",
    "        non_zero_indices = np.nonzero(binary_mask)\n",
    "        if len(non_zero_indices[0]) == 0 or len(non_zero_indices[1]) == 0:\n",
    "            return None\n",
    "        min_row, min_col = np.min(non_zero_indices[0]), np.min(non_zero_indices[1])\n",
    "        max_row, max_col = np.max(non_zero_indices[0]), np.max(non_zero_indices[1])\n",
    "\n",
    "        bounding_box ={\n",
    "            'min_row': min_row,\n",
    "            'min_col': min_col,\n",
    "            'max_row': max_row,\n",
    "            'max_col': max_col\n",
    "        }\n",
    "        return bounding_box\n",
    "\n",
    "\n",
    "    def crop_image_by_bounding_box(self, image, bounding_box):\n",
    "        min_row, min_col = bounding_box['min_row'], bounding_box['min_col']\n",
    "        max_row, max_col = bounding_box['max_row'], bounding_box['max_col']\n",
    "        cropped_image = image[min_row:max_row + 1, min_col:max_col + 1, :]\n",
    "        cropped_resized = cv2.resize(cropped_image, (224, 224))\n",
    "        return cropped_resized\n",
    "\n",
    "\n",
    "    def apply_black_rectangle_by_bounding_box(self, image, bounding_box):\n",
    "        min_row, min_col = bounding_box['min_row'], bounding_box['min_col']\n",
    "        max_row, max_col = 299, bounding_box['max_col']\n",
    "        test_img = image.copy()\n",
    "        test_img = cv2.rectangle(test_img, (min_col, min_row), (max_col, max_row), (0, 0, 0), thickness=cv2.FILLED)\n",
    "        return test_img\n",
    "\n",
    "    \n",
    "    def process_img(self, img): \n",
    "        self.img = img\n",
    "        self.heatmap_1 = self.generate_heatmap(img)\n",
    "        bounding_box_1 = self.get_bounding_box(self.heatmap_1)\n",
    "        self.carpal_img = self.crop_image_by_bounding_box(img, bounding_box_1)\n",
    "        self.masked_img = self.apply_black_rectangle_by_bounding_box(img, bounding_box_1)\n",
    "        self.heatmap_2 = self.generate_heatmap(self.masked_img)\n",
    "        bounding_box_2 = self.get_bounding_box(self.heatmap_2)\n",
    "        self.metacarpal_img = self.crop_image_by_bounding_box(img, bounding_box_2)\n",
    "    \n",
    "    \n",
    "    def save_cropped_img(self, metacarpal_path, carpal_path):\n",
    "        cv2.imwrite(metacarpal_path, self.metacarpal_img)\n",
    "        cv2.imwrite(carpal_path, self.carpal_img)\n",
    "        \n",
    "        \n",
    "    def show_heatmaps(self):\n",
    "        fig, (ax1, ax2 )= plt.subplots(1,2)\n",
    "\n",
    "        ax1.set_title('carpal')\n",
    "        ax2.set_title('metacarpal')\n",
    "        \n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "        ax1.imshow(self.img)\n",
    "        ax1.imshow(self.heatmap_1, cmap='jet', alpha=0.5)\n",
    "\n",
    "        ax2.imshow(self.masked_img)\n",
    "        ax2.imshow(self.heatmap_2, cmap='jet', alpha=0.5)\n",
    "        plt.show()\n",
    "        \n",
    "            \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:42:58.008391600Z",
     "start_time": "2024-01-26T12:42:57.983142800Z"
    }
   },
   "id": "ed09a667f3f29f73",
   "execution_count": 133
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "roi_extractor = RoiExtractor()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:43:01.749741800Z",
     "start_time": "2024-01-26T12:42:58.535479800Z"
    }
   },
   "id": "b202847ba515ba3f",
   "execution_count": 134
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roi_extractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mroi_extractor\u001B[49m\u001B[38;5;241m.\u001B[39mprocess_img(X_val[\u001B[38;5;241m178\u001B[39m])\n",
      "\u001B[1;31mNameError\u001B[0m: name 'roi_extractor' is not defined"
     ]
    }
   ],
   "source": [
    "roi_extractor.process_img(X_val[178])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:55:44.953084800Z",
     "start_time": "2024-01-26T12:55:44.528771500Z"
    }
   },
   "id": "568d246a2e185185",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roi_extractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mroi_extractor\u001B[49m\u001B[38;5;241m.\u001B[39mshow_heatmaps()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'roi_extractor' is not defined"
     ]
    }
   ],
   "source": [
    "roi_extractor.show_heatmaps()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-26T12:56:02.341925900Z",
     "start_time": "2024-01-26T12:56:02.306982500Z"
    }
   },
   "id": "5ad0d2365ad63498",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving Roi images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0581e2032504932"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# for index ,img in enumerate(X_val):\n",
    "#     roi_extractor.process_img(img)\n",
    "#     roi_extractor.save_cropped_img(f'./cropped_imag/metacarpal/training/{index}.png',\n",
    "#                                    f'./cropped_images_png/carpal/validation/{index}.png')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-26T12:55:44.955301900Z"
    }
   },
   "id": "a4ba453b2b514cb1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e0fdea71921c7948"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
